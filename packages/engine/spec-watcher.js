#!/usr/bin/env node

/**
 * Spec Watcher: Weekly crawl the vendor spec URLs to detect material changes
 * 
 * This script can be run in CI to open GitHub issues when specs drift
 * Usage: node spec-watcher.js [--create-issue]
 */

const { templates } = require('./dist/index.js');
const fs = require('fs');
const path = require('path');

// Simple hash function for content comparison
function simpleHash(str) {
  let hash = 0;
  for (let i = 0; i < str.length; i++) {
    const char = str.charCodeAt(i);
    hash = ((hash << 5) - hash) + char;
    hash = hash & hash; // Convert to 32-bit integer
  }
  return Math.abs(hash).toString(16);
}

// Extract meaningful content for comparison (remove timestamps, dynamic content)
function extractSignificantContent(html) {
  return html
    .replace(/\d{4}-\d{2}-\d{2}/g, 'DATE') // Remove dates
    .replace(/\d{2}:\d{2}:\d{2}/g, 'TIME') // Remove times
    .replace(/Last updated:.*?\n/gi, '') // Remove "last updated" lines
    .replace(/Updated on:.*?\n/gi, '') // Remove "updated on" lines
    .replace(/<script.*?<\/script>/gsi, '') // Remove scripts
    .replace(/<!--.*?-->/gs, '') // Remove comments
    .replace(/\s+/g, ' ') // Normalize whitespace
    .trim();
}

async function fetchUrlContent(url) {
  try {
    // Note: In a real implementation, you'd use fetch() or a proper HTTP client
    // This is a placeholder for the concept
    console.log(`[INFO] Would fetch: ${url}`);
    
    // Simulate fetching content
    const mockContent = `
      <html>
        <head><title>Mock Spec</title></head>
        <body>
          <h1>CSV Import Specification</h1>
          <p>Required headers: Title, Handle, Status</p>
          <p>File format: UTF-8 encoding required</p>
          <p>Last updated: 2025-01-14</p>
        </body>
      </html>
    `;
    
    return {
      url,
      content: mockContent,
      hash: simpleHash(extractSignificantContent(mockContent)),
      timestamp: new Date().toISOString()
    };
  } catch (error) {
    console.error(`[ERROR] Failed to fetch ${url}: ${error.message}`);
    return null;
  }
}

async function loadPreviousHashes() {
  const hashFile = path.join(__dirname, 'spec-hashes.json');
  try {
    if (fs.existsSync(hashFile)) {
      const data = fs.readFileSync(hashFile, 'utf8');
      return JSON.parse(data);
    }
  } catch (error) {
    console.error(`[ERROR] Failed to load previous hashes: ${error.message}`);
  }
  return {};
}

async function savePreviousHashes(hashes) {
  const hashFile = path.join(__dirname, 'spec-hashes.json');
  try {
    fs.writeFileSync(hashFile, JSON.stringify(hashes, null, 2));
    console.log(`[INFO] Saved hashes to ${hashFile}`);
  } catch (error) {
    console.error(`[ERROR] Failed to save hashes: ${error.message}`);
  }
}

function createGitHubIssue(template, changedUrls) {
  const issueTitle = `Spec drift detected for ${template.title} template`;
  const issueBody = `
## Specification Drift Detected

The following vendor specification URLs have changed significantly:

${changedUrls.map(url => `- ${url}`).join('\n')}

**Template Details:**
- Template: ${template.title}
- Template Version: ${template.templateVersion}
- Rule Version: ${template.ruleVersion}
- Last Verified: ${template.lastVerified}

**Action Required:**
1. Review the changed specifications
2. Update template fields and validation rules if necessary
3. Update templateVersion and lastVerified dates
4. Run full test suite to ensure compatibility
5. Update documentation contracts in docs/

**All Source URLs:**
${template.sourceUrls.map(url => `- ${url}`).join('\n')}

---
*This issue was automatically generated by the spec watcher. Please review and update the template as needed.*
  `.trim();

  console.log(`[DRIFT] GitHub Issue would be created:`);
  console.log(`Title: ${issueTitle}`);
  console.log(`Body:\n${issueBody}`);
  console.log('');
  
  // In a real implementation, this would use GitHub API to create the issue
  return { title: issueTitle, body: issueBody };
}

async function checkSpecDrift(createIssues = false) {
  console.log('🔍 SPECIFICATION DRIFT DETECTION\n');
  
  const previousHashes = await loadPreviousHashes();
  const currentHashes = {};
  const driftDetected = [];
  
  for (const [templateKey, template] of Object.entries(templates)) {
    console.log(`Checking ${template.title}...`);
    
    const templateHashes = {};
    const changedUrls = [];
    
    for (const url of template.sourceUrls) {
      const result = await fetchUrlContent(url);
      
      if (result) {
        templateHashes[url] = {
          hash: result.hash,
          timestamp: result.timestamp
        };
        
        const previousHash = previousHashes[templateKey]?.[url]?.hash;
        
        if (previousHash && previousHash !== result.hash) {
          console.log(`  ⚠️  DRIFT: ${url}`);
          console.log(`      Previous: ${previousHash}`);
          console.log(`      Current:  ${result.hash}`);
          changedUrls.push(url);
        } else if (previousHash) {
          console.log(`  ✅ No change: ${url}`);
        } else {
          console.log(`  🆕 New tracking: ${url}`);
        }
      }
    }
    
    currentHashes[templateKey] = templateHashes;
    
    if (changedUrls.length > 0) {
      driftDetected.push({
        template,
        changedUrls
      });
      
      if (createIssues) {
        createGitHubIssue(template, changedUrls);
      }
    }
    
    console.log('');
  }
  
  await savePreviousHashes(currentHashes);
  
  // Summary
  console.log('📊 DRIFT DETECTION SUMMARY');
  console.log(`- Templates checked: ${Object.keys(templates).length}`);
  console.log(`- URLs monitored: ${Object.values(templates).reduce((sum, t) => sum + t.sourceUrls.length, 0)}`);
  console.log(`- Drift detected: ${driftDetected.length} templates`);
  
  if (driftDetected.length === 0) {
    console.log('\n🎉 No specification drift detected. All templates are up to date!');
  } else {
    console.log('\n⚠️  Specification drift detected:');
    for (const drift of driftDetected) {
      console.log(`   - ${drift.template.title}: ${drift.changedUrls.length} URLs changed`);
    }
    
    if (createIssues) {
      console.log('\n📝 GitHub issues would be created for drift detection.');
    } else {
      console.log('\n💡 Run with --create-issue to generate GitHub issues for detected drift.');
    }
  }
  
  return driftDetected.length === 0;
}

// Usage and scheduling information
function showUsageInfo() {
  console.log('📅 SPEC WATCHER SETUP\n');
  
  console.log('This tool should be run weekly to detect specification changes.');
  console.log('Recommended setup:\n');
  
  console.log('1. GitHub Actions (weekly cron):');
  console.log('```yaml');
  console.log('name: Spec Drift Detection');
  console.log('on:');
  console.log('  schedule:');
  console.log('    - cron: "0 9 * * 1"  # Every Monday at 9 AM UTC');
  console.log('  workflow_dispatch:');
  console.log('');
  console.log('jobs:');
  console.log('  check-drift:');
  console.log('    runs-on: ubuntu-latest');
  console.log('    steps:');
  console.log('      - uses: actions/checkout@v4');
  console.log('      - uses: actions/setup-node@v4');
  console.log('      - run: npm install');
  console.log('      - run: node packages/engine/spec-watcher.js --create-issue');
  console.log('        env:');
  console.log('          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}');
  console.log('```\n');
  
  console.log('2. Manual check:');
  console.log('   node spec-watcher.js\n');
  
  console.log('3. Local cron (weekly):');
  console.log('   0 9 * * 1 cd /path/to/schemamap && node packages/engine/spec-watcher.js\n');
}

async function main() {
  const args = process.argv.slice(2);
  
  if (args.includes('--help') || args.includes('-h')) {
    showUsageInfo();
    return;
  }
  
  const createIssues = args.includes('--create-issue');
  
  if (args.includes('--info')) {
    showUsageInfo();
    return;
  }
  
  const success = await checkSpecDrift(createIssues);
  process.exit(success ? 0 : 1);
}

if (require.main === module) {
  main().catch(error => {
    console.error(`[FATAL] ${error.message}`);
    process.exit(1);
  });
}

module.exports = { checkSpecDrift, extractSignificantContent, simpleHash };